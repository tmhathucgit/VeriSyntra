print("="*70, flush=True)
print("STEP 2: BILINGUAL DATA INGESTION", flush=True)
print("="*70 + "\n", flush=True)

# Generate bilingual synthetic data
print("üåè Generating BILINGUAL synthetic PDPL dataset (70% Vietnamese + 30% English)...", flush=True)

import json
import random
from datetime import datetime

# PDPL Categories
PDPL_CATEGORIES_VI = {
    0: "T√≠nh h·ª£p ph√°p, c√¥ng b·∫±ng v√† minh b·∫°ch",
    1: "H·∫°n ch·∫ø m·ª•c ƒë√≠ch",
    2: "T·ªëi thi·ªÉu h√≥a d·ªØ li·ªáu",
    3: "T√≠nh ch√≠nh x√°c",
    4: "H·∫°n ch·∫ø l∆∞u tr·ªØ",
    5: "T√≠nh to√†n v·∫πn v√† b·∫£o m·∫≠t",
    6: "Tr√°ch nhi·ªám gi·∫£i tr√¨nh",
    7: "Quy·ªÅn c·ªßa ch·ªß th·ªÉ d·ªØ li·ªáu"
}

PDPL_CATEGORIES_EN = {
    0: "Lawfulness, fairness and transparency",
    1: "Purpose limitation",
    2: "Data minimization",
    3: "Accuracy",
    4: "Storage limitation",
    5: "Integrity and confidentiality",
    6: "Accountability",
    7: "Data subject rights"
}

# Vietnamese companies
VIETNAMESE_COMPANIES = ['VNG', 'FPT', 'Viettel', 'Shopee', 'Lazada', 'Tiki',
                        'VPBank', 'Techcombank', 'Grab', 'MoMo', 'ZaloPay']

# English companies
ENGLISH_COMPANIES = ['TechCorp', 'DataSystems Inc', 'SecureData Ltd', 'InfoProtect Co',
                     'CloudVault', 'PrivacyFirst Inc', 'SafeData Solutions', 'DataGuard Corp',
                     'TrustBank', 'SecureFinance Ltd', 'E-Commerce Global', 'OnlineMarket Inc']

# Vietnamese templates by region
TEMPLATES_VI = {
    0: {
        'bac': ["C√¥ng ty {company} c·∫ßn ph·∫£i thu th·∫≠p d·ªØ li·ªáu c√° nh√¢n m·ªôt c√°ch h·ª£p ph√°p, c√¥ng b·∫±ng v√† minh b·∫°ch theo quy ƒë·ªãnh c·ªßa PDPL 2025.",
                "C√°c t·ªï ch·ª©c c·∫ßn ph·∫£i ƒë·∫£m b·∫£o t√≠nh h·ª£p ph√°p khi thu th·∫≠p v√† x·ª≠ l√Ω d·ªØ li·ªáu c√° nh√¢n c·ªßa kh√°ch h√†ng.",
                "Doanh nghi·ªáp {company} c·∫ßn ph·∫£i th√¥ng b√°o r√µ r√†ng cho ch·ªß th·ªÉ d·ªØ li·ªáu v·ªÅ m·ª•c ƒë√≠ch thu th·∫≠p th√¥ng tin."],
        'trung': ["C√¥ng ty {company} c·∫ßn thu th·∫≠p d·ªØ li·ªáu c√° nh√¢n h·ª£p ph√°p v√† c√¥ng khai theo lu·∫≠t PDPL.",
                  "T·ªï ch·ª©c c·∫ßn b·∫£o ƒë·∫£m c√¥ng b·∫±ng trong vi·ªác x·ª≠ l√Ω th√¥ng tin kh√°ch h√†ng."],
        'nam': ["C√¥ng ty {company} c·∫ßn thu th·∫≠p d·ªØ li·ªáu c·ªßa h·ªç m·ªôt c√°ch h·ª£p ph√°p v√† c√¥ng b·∫±ng.",
                "T·ªï ch·ª©c c·∫ßn ƒë·∫£m b·∫£o minh b·∫°ch khi x·ª≠ l√Ω th√¥ng tin c√° nh√¢n."]
    },
    1: {
        'bac': ["D·ªØ li·ªáu c√° nh√¢n ch·ªâ ƒë∆∞·ª£c s·ª≠ d·ª•ng cho c√°c m·ª•c ƒë√≠ch ƒë√£ th√¥ng b√°o tr∆∞·ªõc cho ch·ªß th·ªÉ d·ªØ li·ªáu.",
                "C√¥ng ty {company} c·∫ßn ph·∫£i h·∫°n ch·∫ø vi·ªác s·ª≠ d·ª•ng d·ªØ li·ªáu theo ƒë√∫ng m·ª•c ƒë√≠ch ƒë√£ c√¥ng b·ªë."],
        'trung': ["D·ªØ li·ªáu ch·ªâ d√πng cho m·ª•c ƒë√≠ch ƒë√£ n√≥i v·ªõi ng∆∞·ªùi d√πng tr∆∞·ªõc ƒë√≥.",
                  "C√¥ng ty {company} c·∫ßn gi·ªõi h·∫°n vi·ªác d√πng d·ªØ li·ªáu theo m·ª•c ƒë√≠ch ban ƒë·∫ßu."],
        'nam': ["D·ªØ li·ªáu c·ªßa h·ªç ch·ªâ ƒë∆∞·ª£c d√πng cho m·ª•c ƒë√≠ch ƒë√£ n√≥i tr∆∞·ªõc.",
                "C√¥ng ty {company} c·∫ßn h·∫°n ch·∫ø d√πng d·ªØ li·ªáu ƒë√∫ng m·ª•c ƒë√≠ch."]
    },
    2: {
        'bac': ["C√¥ng ty {company} ch·ªâ n√™n thu th·∫≠p d·ªØ li·ªáu c√° nh√¢n c·∫ßn thi·∫øt cho m·ª•c ƒë√≠ch c·ª• th·ªÉ.",
                "T·ªï ch·ª©c c·∫ßn ph·∫£i h·∫°n ch·∫ø thu th·∫≠p d·ªØ li·ªáu ·ªü m·ª©c t·ªëi thi·ªÉu c·∫ßn thi·∫øt."],
        'trung': ["C√¥ng ty {company} ch·ªâ n√™n l·∫•y d·ªØ li·ªáu c·∫ßn thi·∫øt cho m·ª•c ƒë√≠ch c·ª• th·ªÉ.",
                  "T·ªï ch·ª©c c·∫ßn h·∫°n ch·∫ø thu th·∫≠p d·ªØ li·ªáu ·ªü m·ª©c t·ªëi thi·ªÉu."],
        'nam': ["C√¥ng ty {company} ch·ªâ n√™n l·∫•y d·ªØ li·ªáu c·ªßa h·ªç khi th·ª±c s·ª± c·∫ßn.",
                "T·ªï ch·ª©c c·∫ßn h·∫°n ch·∫ø l·∫•y th√¥ng tin ·ªü m·ª©c t·ªëi thi·ªÉu."]
    },
    3: {
        'bac': ["C√¥ng ty {company} ph·∫£i ƒë·∫£m b·∫£o d·ªØ li·ªáu c√° nh√¢n ƒë∆∞·ª£c c·∫≠p nh·∫≠t ch√≠nh x√°c v√† k·ªãp th·ªùi.",
                "D·ªØ li·ªáu kh√¥ng ch√≠nh x√°c c·∫ßn ƒë∆∞·ª£c s·ª≠a ch·ªØa ho·∫∑c x√≥a ngay l·∫≠p t·ª©c."],
        'trung': ["C√¥ng ty {company} ph·∫£i ƒë·∫£m b·∫£o d·ªØ li·ªáu c√° nh√¢n ƒë∆∞·ª£c c·∫≠p nh·∫≠t ch√≠nh x√°c.",
                  "D·ªØ li·ªáu sai c·∫ßn ƒë∆∞·ª£c s·ª≠a ho·∫∑c x√≥a ngay."],
        'nam': ["C√¥ng ty {company} ph·∫£i ƒë·∫£m b·∫£o d·ªØ li·ªáu c·ªßa h·ªç ƒë∆∞·ª£c c·∫≠p nh·∫≠t ƒë√∫ng.",
                "D·ªØ li·ªáu sai c·ªßa h·ªç c·∫ßn ƒë∆∞·ª£c s·ª≠a ho·∫∑c x√≥a ngay."]
    },
    4: {
        'bac': ["C√¥ng ty {company} ch·ªâ ƒë∆∞·ª£c l∆∞u tr·ªØ d·ªØ li·ªáu c√° nh√¢n trong th·ªùi gian c·∫ßn thi·∫øt.",
                "T·ªï ch·ª©c ph·∫£i x√≥a d·ªØ li·ªáu c√° nh√¢n khi kh√¥ng c√≤n m·ª•c ƒë√≠ch s·ª≠ d·ª•ng h·ª£p ph√°p."],
        'trung': ["C√¥ng ty {company} ch·ªâ ƒë∆∞·ª£c l∆∞u d·ªØ li·ªáu c√° nh√¢n trong th·ªùi gian c·∫ßn thi·∫øt.",
                  "T·ªï ch·ª©c ph·∫£i x√≥a d·ªØ li·ªáu khi kh√¥ng c√≤n d√πng n·ªØa."],
        'nam': ["C√¥ng ty {company} ch·ªâ ƒë∆∞·ª£c l∆∞u d·ªØ li·ªáu c·ªßa h·ªç trong th·ªùi gian c·∫ßn.",
                "T·ªï ch·ª©c ph·∫£i x√≥a d·ªØ li·ªáu c·ªßa h·ªç khi kh√¥ng d√πng n·ªØa."]
    },
    5: {
        'bac': ["C√¥ng ty {company} ph·∫£i b·∫£o v·ªá d·ªØ li·ªáu c√° nh√¢n kh·ªèi truy c·∫≠p tr√°i ph√©p.",
                "C√°c bi·ªán ph√°p b·∫£o m·∫≠t th√≠ch h·ª£p c·∫ßn ƒë∆∞·ª£c √°p d·ª•ng ƒë·ªÉ b·∫£o v·ªá d·ªØ li·ªáu."],
        'trung': ["C√¥ng ty {company} ph·∫£i b·∫£o v·ªá d·ªØ li·ªáu c√° nh√¢n kh·ªèi truy c·∫≠p tr√°i ph√©p.",
                  "Bi·ªán ph√°p b·∫£o m·∫≠t c·∫ßn ƒë∆∞·ª£c √°p d·ª•ng ƒë·ªÉ b·∫£o v·ªá d·ªØ li·ªáu."],
        'nam': ["C√¥ng ty {company} ph·∫£i b·∫£o v·ªá d·ªØ li·ªáu c·ªßa h·ªç kh·ªèi truy c·∫≠p tr√°i ph√©p.",
                "Bi·ªán ph√°p b·∫£o m·∫≠t c·∫ßn ƒë∆∞·ª£c d√πng ƒë·ªÉ b·∫£o v·ªá d·ªØ li·ªáu c·ªßa h·ªç."]
    },
    6: {
        'bac': ["C√¥ng ty {company} ph·∫£i ch·ªãu tr√°ch nhi·ªám v·ªÅ vi·ªác tu√¢n th·ªß c√°c quy ƒë·ªãnh PDPL.",
                "T·ªï ch·ª©c c·∫ßn c√≥ h·ªì s∆° ch·ª©ng minh vi·ªác tu√¢n th·ªß b·∫£o v·ªá d·ªØ li·ªáu c√° nh√¢n."],
        'trung': ["C√¥ng ty {company} ph·∫£i ch·ªãu tr√°ch nhi·ªám v·ªÅ vi·ªác tu√¢n th·ªß PDPL.",
                  "T·ªï ch·ª©c c·∫ßn c√≥ h·ªì s∆° ch·ª©ng minh tu√¢n th·ªß b·∫£o v·ªá d·ªØ li·ªáu."],
        'nam': ["C√¥ng ty {company} ph·∫£i ch·ªãu tr√°ch nhi·ªám v·ªÅ vi·ªác tu√¢n th·ªß PDPL.",
                "T·ªï ch·ª©c c·∫ßn c√≥ h·ªì s∆° ch·ª©ng minh h·ªç tu√¢n th·ªß b·∫£o v·ªá d·ªØ li·ªáu."]
    },
    7: {
        'bac': ["Ch·ªß th·ªÉ d·ªØ li·ªáu c√≥ quy·ªÅn truy c·∫≠p, s·ª≠a ƒë·ªïi ho·∫∑c x√≥a d·ªØ li·ªáu c√° nh√¢n c·ªßa m√¨nh.",
                "C√¥ng ty {company} ph·∫£i t√¥n tr·ªçng quy·ªÅn c·ªßa ng∆∞·ªùi d√πng ƒë·ªëi v·ªõi d·ªØ li·ªáu c√° nh√¢n."],
        'trung': ["Ch·ªß th·ªÉ d·ªØ li·ªáu c√≥ quy·ªÅn truy c·∫≠p, s·ª≠a ho·∫∑c x√≥a d·ªØ li·ªáu c·ªßa m√¨nh.",
                  "C√¥ng ty {company} ph·∫£i t√¥n tr·ªçng quy·ªÅn c·ªßa ng∆∞·ªùi d√πng v·ªÅ d·ªØ li·ªáu."],
        'nam': ["Ch·ªß th·ªÉ d·ªØ li·ªáu c√≥ quy·ªÅn xem, s·ª≠a ho·∫∑c x√≥a d·ªØ li·ªáu c·ªßa h·ªç.",
                "C√¥ng ty {company} ph·∫£i t√¥n tr·ªçng quy·ªÅn c·ªßa h·ªç v·ªÅ d·ªØ li·ªáu c√° nh√¢n."]
    }
}

# English templates by style
TEMPLATES_EN = {
    0: {
        'formal': ["Company {company} must collect personal data in a lawful, fair and transparent manner in accordance with PDPL 2025.",
                   "Organizations need to ensure lawfulness when collecting and processing customer personal data."],
        'business': ["Company {company} needs to collect data legally and fairly according to PDPL standards.",
                     "Organizations should ensure fairness when handling customer information."]
    },
    1: {
        'formal': ["Personal data may only be used for purposes previously disclosed to the data subject.",
                   "Company {company} must limit data usage to stated purposes only."],
        'business': ["Data can only be used for purposes already told to users.",
                     "Company {company} needs to limit data use to original purposes."]
    },
    2: {
        'formal': ["Company {company} should only collect personal data necessary for specific purposes.",
                   "Organizations must limit data collection to the minimum necessary."],
        'business': ["Company {company} should only collect data needed for specific purposes.",
                     "Organizations need to limit data collection to minimum levels."]
    },
    3: {
        'formal': ["Company {company} must ensure personal data is updated accurately and timely.",
                   "Inaccurate data must be corrected or deleted immediately."],
        'business': ["Company {company} must ensure personal data is updated correctly.",
                     "Wrong data needs to be fixed or deleted right away."]
    },
    4: {
        'formal': ["Company {company} may only store personal data for the necessary period.",
                   "Organizations must delete personal data when there is no longer a lawful purpose."],
        'business': ["Company {company} can only store personal data for necessary time.",
                     "Organizations must delete data when no longer needed."]
    },
    5: {
        'formal': ["Company {company} must protect personal data from unauthorized access.",
                   "Appropriate security measures must be applied to protect data."],
        'business': ["Company {company} must protect personal data from unauthorized access.",
                     "Security measures need to be used to protect data."]
    },
    6: {
        'formal': ["Company {company} must be responsible for compliance with PDPL regulations.",
                   "Organizations need records proving personal data protection compliance."],
        'business': ["Company {company} must be accountable for PDPL compliance.",
                     "Organizations need records proving data protection compliance."]
    },
    7: {
        'formal': ["Data subjects have the right to access, modify or delete their personal data.",
                   "Company {company} must respect users' rights to personal data."],
        'business': ["Data subjects have right to access, modify or delete their data.",
                     "Company {company} must respect users' rights to personal data."]
    }
}

# Generate bilingual dataset (70% Vietnamese, 30% English)
num_samples = 5000
vietnamese_samples = int(num_samples * 0.7)  # 3500
english_samples = num_samples - vietnamese_samples  # 1500

dataset = []

# Generate Vietnamese examples (70%)
print(f"üáªüá≥ Generating {vietnamese_samples} Vietnamese examples (PRIMARY - 70%)...", flush=True)
vi_per_category = vietnamese_samples // 8
vi_per_region = vi_per_category // 3

for category in range(8):
    for region in ['bac', 'trung', 'nam']:
        templates = TEMPLATES_VI.get(category, {}).get(region, [])
        for _ in range(vi_per_region):
            template = random.choice(templates)
            company = random.choice(VIETNAMESE_COMPANIES)
            text = template.format(company=company)

            dataset.append({
                'text': text,
                'label': category,
                'category_name_vi': PDPL_CATEGORIES_VI[category],
                'category_name_en': PDPL_CATEGORIES_EN[category],
                'language': 'vi',
                'region': region,
                'source': 'synthetic',
                'quality': 'controlled'
            })

# Generate English examples (30%)
print(f"üá¨üáß Generating {english_samples} English examples (SECONDARY - 30%)...", flush=True)
en_per_category = english_samples // 8
en_per_style = en_per_category // 2

for category in range(8):
    for style in ['formal', 'business']:
        templates = TEMPLATES_EN.get(category, {}).get(style, [])
        for _ in range(en_per_style):
            template = random.choice(templates)
            company = random.choice(ENGLISH_COMPANIES)
            text = template.format(company=company)

            dataset.append({
                'text': text,
                'label': category,
                'category_name_vi': PDPL_CATEGORIES_VI[category],
                'category_name_en': PDPL_CATEGORIES_EN[category],
                'language': 'en',
                'style': style,
                'source': 'synthetic',
                'quality': 'controlled'
            })

# Shuffle
random.shuffle(dataset)

# Split: 70% train, 15% val, 15% test
train_size = int(0.7 * len(dataset))
val_size = int(0.15 * len(dataset))

train_data = dataset[:train_size]
val_data = dataset[train_size:train_size + val_size]
test_data = dataset[train_size + val_size:]

# Count languages in each split
def count_languages(data):
    vi_count = sum(1 for item in data if item.get('language') == 'vi')
    en_count = sum(1 for item in data if item.get('language') == 'en')
    return vi_count, en_count

train_vi, train_en = count_languages(train_data)
val_vi, val_en = count_languages(val_data)
test_vi, test_en = count_languages(test_data)

# Save to JSONL
import os
os.makedirs('data', exist_ok=True)
print("üìÅ Created 'data' directory", flush=True)

with open('data/train.jsonl', 'w', encoding='utf-8') as f:
    for item in train_data:
        f.write(json.dumps(item, ensure_ascii=False) + '\n')

with open('data/val.jsonl', 'w', encoding='utf-8') as f:
    for item in val_data:
        f.write(json.dumps(item, ensure_ascii=False) + '\n')

with open('data/test.jsonl', 'w', encoding='utf-8') as f:
    for item in test_data:
        f.write(json.dumps(item, ensure_ascii=False) + '\n')

# Verify files created
files_created = [
    ('data/train.jsonl', os.path.exists('data/train.jsonl')),
    ('data/val.jsonl', os.path.exists('data/val.jsonl')),
    ('data/test.jsonl', os.path.exists('data/test.jsonl'))
]
print("\nüìã File verification:", flush=True)
for filename, exists in files_created:
    status = "‚úÖ" if exists else "‚ùå"
    print(f"   {status} {filename}", flush=True)

if not all(exists for _, exists in files_created):
    raise FileNotFoundError("Failed to create data files!")

print(f"\n‚úÖ Bilingual synthetic dataset generated:", flush=True)
print(f"   Train: {len(train_data)} examples ({train_vi} VI + {train_en} EN)", flush=True)
print(f"   Validation: {len(val_data)} examples ({val_vi} VI + {val_en} EN)", flush=True)
print(f"   Test: {len(test_data)} examples ({test_vi} VI + {test_en} EN)", flush=True)
print(f"   Total: {len(dataset)} examples", flush=True)
print(f"\nüìä Language Distribution:", flush=True)
print(f"   Vietnamese (PRIMARY): {train_vi + val_vi + test_vi} ({(train_vi + val_vi + test_vi) / len(dataset) * 100:.1f}%)", flush=True)
print(f"   English (SECONDARY):  {train_en + val_en + test_en} ({(train_en + val_en + test_en) / len(dataset) * 100:.1f}%)", flush=True)

print("\n‚úÖ Bilingual data ingestion complete!\n", flush=True)