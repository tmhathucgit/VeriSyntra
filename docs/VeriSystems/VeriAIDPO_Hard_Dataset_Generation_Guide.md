# VeriAIDPO - Hard Dataset Generation Guide with Ambiguity
## Vietnamese PDPL 2025 - Production-Grade Training Data

**Document Version**: 1.0  
**Created**: October 14, 2025  
**Purpose**: Generate challenging, ambiguous datasets for robust Vietnamese model training  
**Target**: VeriAIDPO_Principles_VI and all future Vietnamese models

---

## üéØ Problem with Current Dataset

### **Current Issues (from VeriAIDPO_Colab_Training_CLEAN.ipynb)**:

```python
# TOO SIMPLE - Easy keyword matching
"C√¥ng ty {company} c·∫ßn thu th·∫≠p d·ªØ li·ªáu m·ªôt c√°ch h·ª£p ph√°p trong lƒ©nh v·ª±c {context}."
# Problem: "h·ª£p ph√°p" = instant Lawfulness classification

"D·ªØ li·ªáu {context} ch·ªâ ƒë∆∞·ª£c s·ª≠ d·ª•ng cho m·ª•c ƒë√≠ch ƒë√£ th√¥ng b√°o."
# Problem: "m·ª•c ƒë√≠ch" = instant Purpose Limitation classification

"D·ªØ li·ªáu {context} ph·∫£i ƒë∆∞·ª£c {company} ƒë·∫£m b·∫£o ch√≠nh x√°c."
# Problem: "ch√≠nh x√°c" = instant Accuracy classification
```

### **Why This is Bad**:
- ‚úÖ **100% accuracy on synthetic data** (model memorizes keywords)
- ‚ùå **Poor generalization** to real Vietnamese business documents
- ‚ùå **No ambiguity handling** (real scenarios overlap multiple principles)
- ‚ùå **Keyword dependency** (model doesn't understand context)
- ‚ùå **Not production-ready** for Vietnamese enterprises

---

## üö® Real-World Vietnamese Compliance Challenges

### **Example 1: Overlapping Principles**

**Real Vietnamese Privacy Policy Excerpt**:
```vietnamese
"Ch√∫ng t√¥i thu th·∫≠p t√™n, email v√† s·ªë ƒëi·ªán tho·∫°i c·ªßa qu√Ω kh√°ch ƒë·ªÉ x·ª≠ l√Ω ƒë∆°n h√†ng. 
Th√¥ng tin n√†y ch·ªâ ƒë∆∞·ª£c s·ª≠ d·ª•ng cho vi·ªác giao h√†ng v√† li√™n h·ªá v·ªÅ ƒë∆°n h√†ng c·ªßa qu√Ω kh√°ch. 
Ch√∫ng t√¥i s·∫Ω l∆∞u tr·ªØ th√¥ng tin n√†y trong 2 nƒÉm k·ªÉ t·ª´ ng√†y mua h√†ng cu·ªëi c√πng."
```

**Multiple Principles Apply**:
- ‚úÖ **Lawfulness** (thu th·∫≠p c√≥ m·ª•c ƒë√≠ch h·ª£p ph√°p)
- ‚úÖ **Purpose Limitation** (ch·ªâ d√πng cho giao h√†ng)
- ‚úÖ **Data Minimization** (ch·ªâ thu t√™n, email, SƒêT)
- ‚úÖ **Storage Limitation** (l∆∞u 2 nƒÉm)

**Challenge**: Model must identify PRIMARY principle (Purpose Limitation in this case)

---

### **Example 2: Subtle Vietnamese Business Context**

**Northern Vietnam (Formal, Government-influenced)**:
```vietnamese
"CƒÉn c·ª© Lu·∫≠t An to√†n th√¥ng tin m·∫°ng v√† Ngh·ªã ƒë·ªãnh 13/2023/Nƒê-CP, ƒë∆°n v·ªã ch√∫ng t√¥i 
th·ª±c hi·ªán thu th·∫≠p d·ªØ li·ªáu c√° nh√¢n c·ªßa c√¥ng d√¢n theo ƒë√∫ng quy ƒë·ªãnh ph√°p lu·∫≠t hi·ªán h√†nh."
```
**Principle**: Lawfulness (formal legal language, government context)

**Southern Vietnam (Business-oriented, Practical)**:
```vietnamese
"C√¥ng ty cam k·∫øt ch·ªâ l·∫•y th√¥ng tin c·∫ßn thi·∫øt ƒë·ªÉ ph·ª•c v·ª• qu√Ω kh√°ch t·ªët nh·∫•t. 
Ch√∫ng t√¥i kh√¥ng thu th·∫≠p th√™m d·ªØ li·ªáu kh√¥ng li√™n quan ƒë·∫øn d·ªãch v·ª•."
```
**Principle**: Data Minimization (practical business language, customer focus)

**Challenge**: Same concept, different regional expression styles

---

### **Example 3: Vietnamese Legal vs Colloquial Language**

**Legal Vietnamese (Government documents)**:
```vietnamese
"B√™n x·ª≠ l√Ω d·ªØ li·ªáu c√≥ nghƒ©a v·ª• ƒë·∫£m b·∫£o t√≠nh ch√≠nh x√°c, ƒë·∫ßy ƒë·ªß v√† c·∫≠p nh·∫≠t c·ªßa 
d·ªØ li·ªáu c√° nh√¢n trong su·ªët qu√° tr√¨nh x·ª≠ l√Ω."
```
**Principle**: Accuracy

**Colloquial Vietnamese (Startup privacy policy)**:
```vietnamese
"Ch√∫ng m√¨nh lu√¥n c·ªë g·∫Øng gi·ªØ th√¥ng tin c·ªßa b·∫°n ƒë∆∞·ª£c ch√≠nh x√°c nh·∫•t. 
N·∫øu ph√°t hi·ªán sai s√≥t, b·∫°n c√≥ th·ªÉ li√™n h·ªá ƒë·ªÉ ch√∫ng m√¨nh s·ª≠a ngay nh√©."
```
**Principle**: Accuracy (same meaning, casual tone)

**Challenge**: Model must handle formal "b√™n x·ª≠ l√Ω" and casual "ch√∫ng m√¨nh"

---

## üí° Hard Dataset Generation Strategy

### **Principle 1: Multi-Principle Overlap Scenarios**

Generate samples where 2-3 principles overlap, requiring contextual understanding:

```python
AMBIGUOUS_SCENARIOS = {
    "lawfulness_purpose_overlap": {
        "vi": [
            "CƒÉn c·ª© h·ª£p ƒë·ªìng cung c·∫•p d·ªãch v·ª•, {company} thu th·∫≠p {context} ƒë·ªÉ th·ª±c hi·ªán nghƒ©a v·ª• h·ª£p ƒë·ªìng v·ªõi kh√°ch h√†ng, ƒë·∫£m b·∫£o vi·ªác s·ª≠ d·ª•ng th√¥ng tin n√†y ch·ªâ ph·ª•c v·ª• cho m·ª•c ƒë√≠ch giao h√†ng v√† thanh to√°n.",
            # PRIMARY: Lawfulness (legal basis: contract)
            # SECONDARY: Purpose Limitation (ch·ªâ cho giao h√†ng)
            
            "Theo quy ƒë·ªãnh t·∫°i ƒêi·ªÅu 13 Lu·∫≠t BVDLCN, {company} x·ª≠ l√Ω d·ªØ li·ªáu {context} cho m·ª•c ƒë√≠ch cung c·∫•p d·ªãch v·ª• ƒë∆∞·ª£c n√™u r√µ trong ch√≠nh s√°ch b·∫£o m·∫≠t, kh√¥ng m·ªü r·ªông sang c√°c m·ª•c ƒë√≠ch kh√°c.",
            # PRIMARY: Purpose Limitation (kh√¥ng m·ªü r·ªông m·ª•c ƒë√≠ch)
            # SECONDARY: Lawfulness (theo quy ƒë·ªãnh ƒêi·ªÅu 13)
        ],
        "primary_label": "varies",  # Context-dependent
        "difficulty": "HARD"
    },
    
    "minimization_storage_overlap": {
        "vi": [
            "{company} ch·ªâ thu th·∫≠p {context} t·ªëi thi·ªÉu c·∫ßn thi·∫øt cho vi·ªác x·ª≠ l√Ω ƒë∆°n h√†ng v√† s·∫Ω x√≥a d·ªØ li·ªáu n√†y sau 6 th√°ng khi kh√¥ng c√≤n s·ª≠ d·ª•ng.",
            # PRIMARY: Storage Limitation (x√≥a sau 6 th√°ng)
            # SECONDARY: Data Minimization (thu t·ªëi thi·ªÉu)
            
            "ƒê·ªÉ tu√¢n th·ªß nguy√™n t·∫Øc t·ªëi thi·ªÉu h√≥a, {company} ch·ªâ y√™u c·∫ßu {context} c·∫ßn thi·∫øt v√† kh√¥ng l∆∞u tr·ªØ th√¥ng tin n√†y qu√° th·ªùi h·∫°n quy ƒë·ªãnh.",
            # PRIMARY: Data Minimization (nguy√™n t·∫Øc t·ªëi thi·ªÉu h√≥a)
            # SECONDARY: Storage Limitation (kh√¥ng l∆∞u qu√° th·ªùi h·∫°n)
        ],
        "primary_label": "varies",
        "difficulty": "HARD"
    },
    
    "accuracy_transparency_overlap": {
        "vi": [
            "{company} c√¥ng khai quy tr√¨nh ki·ªÉm tra v√† c·∫≠p nh·∫≠t {context} ƒë·ªÉ ƒë·∫£m b·∫£o th√¥ng tin lu√¥n ch√≠nh x√°c, ƒë·ªìng th·ªùi cho ph√©p kh√°ch h√†ng xem v√† ch·ªânh s·ª≠a d·ªØ li·ªáu c·ªßa m√¨nh.",
            # PRIMARY: Accuracy (ƒë·∫£m b·∫£o ch√≠nh x√°c)
            # SECONDARY: Transparency (c√¥ng khai quy tr√¨nh)
            
            "Ch√∫ng t√¥i th√¥ng b√°o r√µ r√†ng v·ªÅ vi·ªác thu th·∫≠p {context} v√† cam k·∫øt duy tr√¨ ƒë·ªô ch√≠nh x√°c c·ªßa th√¥ng tin n√†y th√¥ng qua h·ªá th·ªëng t·ª± ƒë·ªông ki·ªÉm tra.",
            # PRIMARY: Transparency (th√¥ng b√°o r√µ r√†ng)
            # SECONDARY: Accuracy (duy tr√¨ ƒë·ªô ch√≠nh x√°c)
        ],
        "primary_label": "varies",
        "difficulty": "VERY_HARD"
    }
}
```

---

### **Principle 2: Regional Vietnamese Variation**

Create same principle with different regional expressions:

```python
REGIONAL_VARIATIONS = {
    "lawfulness": {
        "north": [
            # Formal, government-influenced, legal terminology
            "CƒÉn c·ª© v√†o quy ƒë·ªãnh ph√°p lu·∫≠t hi·ªán h√†nh, ƒë∆°n v·ªã ch√∫ng t√¥i th·ª±c hi·ªán vi·ªác thu th·∫≠p {context}.",
            "Theo Ngh·ªã ƒë·ªãnh 13/2023/Nƒê-CP, {company} ti·∫øn h√†nh x·ª≠ l√Ω d·ªØ li·ªáu c√° nh√¢n v·ªõi c∆° s·ªü ph√°p l√Ω r√µ r√†ng.",
            "ƒê∆°n v·ªã c√≥ vƒÉn b·∫£n ph√°p l√Ω cho ph√©p thu th·∫≠p v√† x·ª≠ l√Ω {context} c·ªßa c√¥ng d√¢n.",
        ],
        "central": [
            # Traditional, consensus-building, balanced formal-informal
            "Doanh nghi·ªáp ch√∫ng t√¥i tu√¢n th·ªß ƒë·∫ßy ƒë·ªß quy ƒë·ªãnh v·ªÅ b·∫£o v·ªá d·ªØ li·ªáu khi thu th·∫≠p {context}.",
            "{company} th·ª±c hi·ªán vi·ªác x·ª≠ l√Ω th√¥ng tin theo ƒë√∫ng c√°c quy ƒë·ªãnh hi·ªán h√†nh c·ªßa ph√°p lu·∫≠t.",
            "Ch√∫ng t√¥i c√≥ ƒë·∫ßy ƒë·ªß c∆° s·ªü ph√°p l√Ω ƒë·ªÉ thu th·∫≠p {context} t·ª´ kh√°ch h√†ng.",
        ],
        "south": [
            # Business-casual, practical, customer-focused
            "C√¥ng ty m√¨nh thu th·∫≠p {context} ho√†n to√†n h·ª£p ph√°p v√† ƒë√∫ng quy ƒë·ªãnh nh√©.",
            "{company} cam k·∫øt thu th·∫≠p th√¥ng tin c·ªßa b·∫°n theo ƒë√∫ng lu·∫≠t Vi·ªát Nam.",
            "Ch√∫ng m√¨nh x·ª≠ l√Ω d·ªØ li·ªáu {context} c√≥ c∆° s·ªü ph√°p l√Ω r√µ r√†ng, b·∫°n y√™n t√¢m.",
        ]
    },
    
    "data_minimization": {
        "north": [
            "ƒê∆°n v·ªã ch·ªâ thu th·∫≠p c√°c d·ªØ li·ªáu {context} c·∫ßn thi·∫øt, tu√¢n th·ªß nguy√™n t·∫Øc t·ªëi thi·ªÉu h√≥a.",
            "{company} √°p d·ª•ng nghi√™m ng·∫∑t nguy√™n t·∫Øc h·∫°n ch·∫ø ph·∫°m vi thu th·∫≠p d·ªØ li·ªáu c√° nh√¢n.",
        ],
        "central": [
            "Doanh nghi·ªáp ch·ªâ y√™u c·∫ßu nh·ªØng th√¥ng tin {context} th·ª±c s·ª± c·∫ßn thi·∫øt cho ho·∫°t ƒë·ªông.",
            "{company} h·∫°n ch·∫ø thu th·∫≠p d·ªØ li·ªáu ·ªü m·ª©c t·ªëi thi·ªÉu c·∫ßn thi·∫øt.",
        ],
        "south": [
            "C√¥ng ty m√¨nh ch·ªâ l·∫•y {context} c·∫ßn thi·∫øt th√¥i, kh√¥ng thu th·∫≠p d∆∞ th·ª´a ƒë√¢u.",
            "{company} ch·ªâ h·ªèi th√¥ng tin th·ª±c s·ª± c·∫ßn cho d·ªãch v·ª•, kh√¥ng h·ªèi th√™m.",
        ]
    }
}
```

---

### **Principle 3: Semantic Ambiguity (No Keywords)**

Generate samples WITHOUT obvious PDPL keywords:

```python
NO_KEYWORD_SAMPLES = {
    "lawfulness": [
        # No "h·ª£p ph√°p", "quy ƒë·ªãnh", "lu·∫≠t" - must understand CONTRACT context
        "{company} thu th·∫≠p {context} d·ª±a tr√™n th·ªèa thu·∫≠n mua b√°n gi·ªØa hai b√™n.",
        "Theo ƒëi·ªÅu kho·∫£n ƒë√£ k√Ω k·∫øt, {company} ƒë∆∞·ª£c quy·ªÅn x·ª≠ l√Ω {context} c·ªßa kh√°ch h√†ng.",
        "Vi·ªác thu th·∫≠p {context} l√† m·ªôt ph·∫ßn c·ªßa h·ª£p ƒë·ªìng d·ªãch v·ª•.",
    ],
    
    "purpose_limitation": [
        # No "m·ª•c ƒë√≠ch" - must understand SCOPE restriction
        "{company} s·ª≠ d·ª•ng {context} cho vi·ªác giao h√†ng, kh√¥ng d√πng cho vi·ªác kh√°c.",
        "Th√¥ng tin {context} ch·ªâ ph·ª•c v·ª• cho ho·∫°t ƒë·ªông v·∫≠n chuy·ªÉn s·∫£n ph·∫©m.",
        "{company} kh√¥ng m·ªü r·ªông ph·∫°m vi s·ª≠ d·ª•ng {context} ngo√†i nh·ªØng g√¨ ƒë√£ th√¥ng b√°o.",
    ],
    
    "data_minimization": [
        # No "t·ªëi thi·ªÉu", "h·∫°n ch·∫ø" - must understand SUFFICIENCY concept
        "{company} ch·ªâ h·ªèi {context} ƒë·ªß ƒë·ªÉ ho√†n th√†nh d·ªãch v·ª•.",
        "Ch√∫ng t√¥i kh√¥ng y√™u c·∫ßu th√¥ng tin {context} kh√¥ng li√™n quan ƒë·∫øn giao d·ªãch.",
        "{company} thu th·∫≠p v·ª´a ƒë·ªß {context} c·∫ßn thi·∫øt, kh√¥ng th·ª´a.",
    ],
    
    "accuracy": [
        # No "ch√≠nh x√°c" - must understand VERIFICATION/CORRECTION
        "{company} cho ph√©p kh√°ch h√†ng ki·ªÉm tra v√† s·ª≠a ƒë·ªïi {context}.",
        "N·∫øu {context} c√≥ sai s√≥t, ch√∫ng t√¥i s·∫Ω c·∫≠p nh·∫≠t ngay.",
        "{company} c√≥ h·ªá th·ªëng ƒë·ªÉ kh√°ch h√†ng x√°c minh l·∫°i {context} c·ªßa m√¨nh.",
    ],
    
    "storage_limitation": [
        # No "l∆∞u tr·ªØ", "th·ªùi h·∫°n" - must understand RETENTION concept
        "{company} gi·ªØ {context} trong 2 nƒÉm sau ƒë√≥ s·∫Ω x√≥a.",
        "Th√¥ng tin {context} ch·ªâ ƒë∆∞·ª£c duy tr√¨ ƒë·∫øn khi h·∫øt m·ª•c ƒë√≠ch s·ª≠ d·ª•ng.",
        "{company} kh√¥ng gi·ªØ {context} m√£i m√£i, s·∫Ω x√≥a khi kh√¥ng c·∫ßn.",
    ]
}
```

---

### **Principle 4: Vietnamese Business Context Complexity**

Embed PDPL principles in realistic Vietnamese business scenarios:

```python
BUSINESS_CONTEXT_SAMPLES = {
    "ecommerce_lawfulness": [
        """Khi anh/ch·ªã ƒë·∫∑t h√†ng tr√™n {company}.vn, ch√∫ng t√¥i c·∫ßn s·ªë ƒëi·ªán tho·∫°i v√† ƒë·ªãa ch·ªâ 
        ƒë·ªÉ shipper li√™n h·ªá giao h√†ng. Vi·ªác n√†y l√† b·∫Øt bu·ªôc ƒë·ªÉ ho√†n t·∫•t ƒë∆°n h√†ng theo 
        h·ª£p ƒë·ªìng mua b√°n gi·ªØa hai b√™n.""",
        # PRIMARY: Lawfulness (legal basis = contract performance)
        # Difficulty: Real e-commerce scenario, multiple clauses
    ],
    
    "fintech_purpose_limitation": [
        """V√≠ ƒëi·ªán t·ª≠ {company} thu th·∫≠p CMND/CCCD c·ªßa qu√Ω kh√°ch ƒë·ªÉ x√°c minh danh t√≠nh 
        theo quy ƒë·ªãnh c·ªßa Ng√¢n h√†ng Nh√† n∆∞·ªõc. Th√¥ng tin n√†y ch·ªâ d√πng cho vi·ªác KYC, 
        kh√¥ng chia s·∫ª cho b√™n th·ª© ba v·ªõi m·ª•c ƒë√≠ch marketing.""",
        # PRIMARY: Purpose Limitation (ch·ªâ d√πng cho KYC)
        # Difficulty: Financial regulation context, multi-purpose scenario
    ],
    
    "healthtech_accuracy": [
        """Th√¥ng tin s·ª©c kh·ªèe trong h·ªì s∆° b·ªánh √°n ƒëi·ªán t·ª≠ c·ªßa {company} c·∫ßn ƒë∆∞·ª£c c·∫≠p nh·∫≠t 
        ch√≠nh x√°c. B√°c sƒ© c√≥ th·ªÉ ch·ªânh s·ª≠a h·ªì s∆° sau m·ªói l·∫ßn kh√°m, v√† b·ªánh nh√¢n ƒë∆∞·ª£c quy·ªÅn 
        y√™u c·∫ßu s·ª≠a ƒë·ªïi n·∫øu ph√°t hi·ªán sai s√≥t.""",
        # PRIMARY: Accuracy (c·∫≠p nh·∫≠t ch√≠nh x√°c, quy·ªÅn s·ª≠a ƒë·ªïi)
        # Difficulty: Healthcare context, professional terminology
    ],
    
    "edtech_data_minimization": [
        """N·ªÅn t·∫£ng h·ªçc online {company} ch·ªâ y√™u c·∫ßu h·ªçc sinh cung c·∫•p h·ªç t√™n, email v√† 
        l·ªõp h·ªçc. Ch√∫ng t√¥i kh√¥ng thu th·∫≠p th√¥ng tin gia ƒë√¨nh, ƒë·ªãa ch·ªâ nh√†, ho·∫∑c s·ªë ƒëi·ªán 
        tho·∫°i ph·ª• huynh tr·ª´ khi c√≥ nhu c·∫ßu li√™n h·ªá kh·∫©n c·∫•p.""",
        # PRIMARY: Data Minimization (ch·ªâ y√™u c·∫ßu h·ªç t√™n, email, l·ªõp)
        # Difficulty: Children's data context, conditional collection
    ]
}
```

---

## üé® Implementation: Hard Dataset Generator for Vietnamese

### **Enhanced Template System**

```python
class VietnameseHardDatasetGenerator:
    """
    Generate production-grade Vietnamese datasets with ambiguity
    """
    
    def __init__(self):
        self.ambiguity_levels = ['EASY', 'MEDIUM', 'HARD', 'VERY_HARD']
        self.regional_styles = ['north', 'central', 'south']
        self.formality_levels = ['legal', 'formal', 'business', 'casual']
        
    def generate_hard_sample(
        self, 
        category_id: int, 
        ambiguity: str = 'HARD',
        region: str = 'south',
        formality: str = 'business'
    ) -> Dict:
        """
        Generate single hard sample with controlled ambiguity
        """
        
        if ambiguity == 'VERY_HARD':
            # Multi-principle overlap, no keywords, complex context
            return self._generate_multi_principle_sample(category_id, region)
            
        elif ambiguity == 'HARD':
            # No obvious keywords, regional variation, business context
            return self._generate_no_keyword_sample(category_id, region, formality)
            
        elif ambiguity == 'MEDIUM':
            # Subtle keywords, some ambiguity, standard business language
            return self._generate_subtle_keyword_sample(category_id, region)
            
        else:  # EASY
            # Clear keywords (similar to current dataset)
            return self._generate_clear_sample(category_id)
    
    def _generate_multi_principle_sample(self, primary_category: int, region: str) -> Dict:
        """
        Generate sample where 2-3 principles overlap
        Model must identify PRIMARY principle from context
        """
        
        if primary_category == 0:  # Lawfulness as PRIMARY
            overlapping_principles = [
                {
                    'text': "CƒÉn c·ª© h·ª£p ƒë·ªìng d·ªãch v·ª• ƒë√£ k√Ω, {company} thu th·∫≠p {context} ƒë·ªÉ th·ª±c hi·ªán nghƒ©a v·ª• giao h√†ng, ƒë·∫£m b·∫£o ch·ªâ s·ª≠ d·ª•ng cho m·ª•c ƒë√≠ch n√†y v√† kh√¥ng chia s·∫ª cho b√™n th·ª© ba.",
                    'primary': 0,  # Lawfulness (h·ª£p ƒë·ªìng = legal basis)
                    'secondary': [1],  # Purpose limitation (ch·ªâ s·ª≠ d·ª•ng cho m·ª•c ƒë√≠ch n√†y)
                    'keywords_to_avoid': ['h·ª£p ph√°p', 'lu·∫≠t'],  # Force context understanding
                },
                {
                    'text': "Theo th·ªèa thu·∫≠n v·ªõi kh√°ch h√†ng, {company} x·ª≠ l√Ω {context} trong ph·∫°m vi cung c·∫•p d·ªãch v·ª•, cam k·∫øt ch·ªâ gi·ªØ th√¥ng tin ƒë·∫øn khi ho√†n t·∫•t giao d·ªãch.",
                    'primary': 0,  # Lawfulness (th·ªèa thu·∫≠n = contract)
                    'secondary': [1, 4],  # Purpose + Storage limitation
                    'keywords_to_avoid': ['h·ª£p ph√°p', 'quy ƒë·ªãnh'],
                }
            ]
            
        elif primary_category == 1:  # Purpose Limitation as PRIMARY
            overlapping_principles = [
                {
                    'text': "{company} s·ª≠ d·ª•ng {context} ch·ªâ ƒë·ªÉ x·ª≠ l√Ω ƒë∆°n h√†ng nh∆∞ ƒë√£ th√¥ng b√°o, kh√¥ng m·ªü r·ªông sang marketing ho·∫∑c chia s·∫ª b√™n th·ª© ba, ƒë·ªìng th·ªùi x√≥a sau 6 th√°ng.",
                    'primary': 1,  # Purpose limitation (kh√¥ng m·ªü r·ªông)
                    'secondary': [4],  # Storage limitation (x√≥a sau 6 th√°ng)
                    'keywords_to_avoid': ['m·ª•c ƒë√≠ch'],  # Force "kh√¥ng m·ªü r·ªông" understanding
                },
                {
                    'text': "Th√¥ng tin {context} thu th·∫≠p t·ª´ kh√°ch h√†ng ch·ªâ ph·ª•c v·ª• cho vi·ªác giao h√†ng v√† thanh to√°n, {company} cam k·∫øt kh√¥ng s·ª≠ d·ª•ng cho b·∫•t k·ª≥ ho·∫°t ƒë·ªông n√†o kh√°c.",
                    'primary': 1,  # Purpose limitation (ch·ªâ ph·ª•c v·ª• giao h√†ng)
                    'secondary': [0],  # Lawfulness (implicit contract basis)
                    'keywords_to_avoid': ['m·ª•c ƒë√≠ch', 'h·∫°n ch·∫ø'],
                }
            ]
        
        # Select one sample and fill with regional business context
        sample = random.choice(overlapping_principles)
        filled_text = self._fill_with_regional_context(sample['text'], region)
        
        return {
            'text': filled_text,
            'label': sample['primary'],
            'ambiguity': 'VERY_HARD',
            'overlapping_principles': sample['secondary'],
            'difficulty_reason': 'Multiple principles overlap, no obvious keywords'
        }
    
    def _generate_no_keyword_sample(self, category_id: int, region: str, formality: str) -> Dict:
        """
        Generate samples WITHOUT obvious PDPL keywords
        Forces model to understand semantic meaning
        """
        
        NO_KEYWORD_TEMPLATES = {
            0: {  # Lawfulness (no "h·ª£p ph√°p", "lu·∫≠t", "quy ƒë·ªãnh")
                'legal': [
                    "D·ª±a tr√™n th·ªèa thu·∫≠n k√Ω k·∫øt gi·ªØa hai b√™n, {company} ƒë∆∞·ª£c quy·ªÅn x·ª≠ l√Ω {context}.",
                    "Theo ƒëi·ªÅu kho·∫£n h·ª£p ƒë·ªìng, vi·ªác thu th·∫≠p {context} l√† b·∫Øt bu·ªôc ƒë·ªÉ th·ª±c hi·ªán d·ªãch v·ª•.",
                ],
                'business': [
                    "Khi ƒëƒÉng k√Ω d·ªãch v·ª•, b·∫°n ƒë√£ ƒë·ªìng √Ω cho {company} s·ª≠ d·ª•ng {context} ƒë·ªÉ ho√†n t·∫•t giao d·ªãch.",
                    "{company} thu th·∫≠p {context} d·ª±a tr√™n s·ª± cho ph√©p c·ªßa kh√°ch h√†ng trong h·ª£p ƒë·ªìng.",
                ],
                'casual': [
                    "B·∫°n ƒë√£ ƒë·ªìng √Ω cho m√¨nh thu th·∫≠p {context} khi ƒë·∫∑t h√†ng r·ªìi nh√©.",
                    "Theo th·ªèa thu·∫≠n mua b√°n, {company} ƒë∆∞·ª£c ph√©p s·ª≠ d·ª•ng {context} c·ªßa b·∫°n.",
                ]
            },
            
            1: {  # Purpose Limitation (no "m·ª•c ƒë√≠ch", "h·∫°n ch·∫ø")
                'legal': [
                    "{company} s·ª≠ d·ª•ng {context} trong ph·∫°m vi cung c·∫•p d·ªãch v·ª•, kh√¥ng m·ªü r·ªông sang ho·∫°t ƒë·ªông kh√°c.",
                    "Th√¥ng tin {context} ch·ªâ ph·ª•c v·ª• cho vi·ªác giao h√†ng, kh√¥ng d√πng cho marketing.",
                ],
                'business': [
                    "{company} ch·ªâ d√πng {context} ƒë·ªÉ x·ª≠ l√Ω ƒë∆°n h√†ng, kh√¥ng chia s·∫ª cho b√™n th·ª© ba.",
                    "D·ªØ li·ªáu {context} ch·ªâ ph·ª•c v·ª• cho ho·∫°t ƒë·ªông v·∫≠n chuy·ªÉn s·∫£n ph·∫©m.",
                ],
                'casual': [
                    "M√¨nh ch·ªâ d√πng {context} ƒë·ªÉ giao h√†ng th√¥i, kh√¥ng l√†m g√¨ kh√°c ƒë√¢u.",
                    "{company} kh√¥ng s·ª≠ d·ª•ng {context} c·ªßa b·∫°n ngo√†i vi·ªác ship h√†ng.",
                ]
            },
            
            2: {  # Data Minimization (no "t·ªëi thi·ªÉu", "h·∫°n ch·∫ø")
                'legal': [
                    "{company} ch·ªâ y√™u c·∫ßu {context} c·∫ßn thi·∫øt ƒë·ªÉ th·ª±c hi·ªán d·ªãch v·ª•, kh√¥ng thu th·∫≠p th√™m.",
                    "Ph·∫°m vi thu th·∫≠p {context} ƒë∆∞·ª£c gi·ªõi h·∫°n ·ªü m·ª©c ƒë·ªß ƒë·ªÉ ho√†n t·∫•t giao d·ªãch.",
                ],
                'business': [
                    "{company} ch·ªâ h·ªèi {context} c·∫ßn thi·∫øt cho ƒë∆°n h√†ng, kh√¥ng y√™u c·∫ßu th√¥ng tin th·ª´a.",
                    "Ch√∫ng t√¥i ch·ªâ thu {context} ƒë·ªß ƒë·ªÉ x·ª≠ l√Ω, kh√¥ng l·∫•y th√™m d·ªØ li·ªáu kh√¥ng li√™n quan.",
                ],
                'casual': [
                    "M√¨nh ch·ªâ h·ªèi {context} c·∫ßn thi·∫øt th√¥i, kh√¥ng h·ªèi lung tung.",
                    "{company} ch·ªâ l·∫•y th√¥ng tin v·ª´a ƒë·ªß, kh√¥ng thu qu√° nhi·ªÅu.",
                ]
            },
            
            3: {  # Accuracy (no "ch√≠nh x√°c", "ƒë√∫ng")
                'legal': [
                    "{company} cho ph√©p kh√°ch h√†ng ki·ªÉm tra v√† ch·ªânh s·ª≠a {context} b·∫•t k·ª≥ l√∫c n√†o.",
                    "N·∫øu ph√°t hi·ªán sai s√≥t trong {context}, kh√°ch h√†ng c√≥ quy·ªÅn y√™u c·∫ßu c·∫≠p nh·∫≠t.",
                ],
                'business': [
                    "{company} h·ªó tr·ª£ kh√°ch h√†ng c·∫≠p nh·∫≠t {context} khi c√≥ thay ƒë·ªïi.",
                    "B·∫°n c√≥ th·ªÉ li√™n h·ªá ƒë·ªÉ s·ª≠a ƒë·ªïi {context} n·∫øu th·∫•y c√≥ l·ªói.",
                ],
                'casual': [
                    "N·∫øu {context} sai, b·∫°n b√°o m√¨nh s·ª≠a ngay nh√©.",
                    "{company} cho ph√©p b·∫°n ki·ªÉm tra v√† ƒë·ªïi {context} b·∫•t c·ª© l√∫c n√†o.",
                ]
            },
            
            4: {  # Storage Limitation (no "l∆∞u tr·ªØ", "th·ªùi h·∫°n")
                'legal': [
                    "{company} gi·ªØ {context} trong 2 nƒÉm sau giao d·ªãch cu·ªëi c√πng, sau ƒë√≥ s·∫Ω x√≥a.",
                    "D·ªØ li·ªáu {context} ch·ªâ ƒë∆∞·ª£c duy tr√¨ ƒë·∫øn khi ho√†n t·∫•t d·ªãch v·ª•.",
                ],
                'business': [
                    "{company} kh√¥ng gi·ªØ {context} m√£i m√£i, s·∫Ω x√≥a sau 6 th√°ng kh√¥ng s·ª≠ d·ª•ng.",
                    "Th√¥ng tin {context} ch·ªâ t·ªìn t·∫°i ƒë·∫øn khi b·∫°n c√≤n l√† kh√°ch h√†ng.",
                ],
                'casual': [
                    "M√¨nh ch·ªâ gi·ªØ {context} trong 1 nƒÉm th√¥i, sau ƒë√≥ x√≥a.",
                    "{company} kh√¥ng l∆∞u {context} l√¢u d√†i, ch·ªâ gi·ªØ khi c·∫ßn.",
                ]
            },
            
            5: {  # Integrity & Confidentiality (no "b·∫£o m·∫≠t", "an to√†n")
                'legal': [
                    "{company} √°p d·ª•ng m√£ h√≥a ƒë·ªÉ b·∫£o v·ªá {context} kh·ªèi truy c·∫≠p tr√°i ph√©p.",
                    "D·ªØ li·ªáu {context} ƒë∆∞·ª£c ki·ªÉm so√°t ch·∫∑t ch·∫Ω, ch·ªâ nh√¢n vi√™n ƒë∆∞·ª£c ph√©p m·ªõi truy c·∫≠p.",
                ],
                'business': [
                    "{company} s·ª≠ d·ª•ng c√¥ng ngh·ªá hi·ªán ƒë·∫°i ƒë·ªÉ b·∫£o v·ªá {context} c·ªßa b·∫°n.",
                    "Th√¥ng tin {context} ƒë∆∞·ª£c gi·ªØ k√≠n, kh√¥ng chia s·∫ª cho b√™n ngo√†i.",
                ],
                'casual': [
                    "M√¨nh m√£ h√≥a {context} c·ªßa b·∫°n ƒë·ªÉ kh√¥ng ai ƒë·ªçc tr·ªôm ƒë∆∞·ª£c.",
                    "{company} b·∫£o v·ªá {context} r·∫•t k·ªπ, y√™n t√¢m nh√©.",
                ]
            },
            
            6: {  # Accountability (no "tr√°ch nhi·ªám", "gi·∫£i tr√¨nh")
                'legal': [
                    "{company} ch·ªâ ƒë·ªãnh DPO ƒë·ªÉ gi√°m s√°t vi·ªác x·ª≠ l√Ω {context}.",
                    "Ch√∫ng t√¥i c√≥ nh√¢n vi√™n chuy√™n tr√°ch qu·∫£n l√Ω v√† ki·ªÉm so√°t {context}.",
                ],
                'business': [
                    "{company} c√≥ b·ªô ph·∫≠n ch·ªãu tr√°ch nhi·ªám v·ªÅ vi·ªác x·ª≠ l√Ω {context}.",
                    "Ch√∫ng t√¥i ch·ªâ ƒë·ªãnh ng∆∞·ªùi ph·ª• tr√°ch ƒë·ªÉ ƒë·∫£m b·∫£o {context} ƒë∆∞·ª£c qu·∫£n l√Ω ƒë√∫ng.",
                ],
                'casual': [
                    "{company} c√≥ ng∆∞·ªùi chuy√™n lo v·ªÅ {context} c·ªßa b·∫°n.",
                    "M√¨nh c√≥ team ri√™ng ƒë·ªÉ qu·∫£n l√Ω {context} cho an to√†n.",
                ]
            },
            
            7: {  # Data Subject Rights (no "quy·ªÅn", "ch·ªß th·ªÉ")
                'legal': [
                    "Kh√°ch h√†ng c√≥ th·ªÉ y√™u c·∫ßu {company} cung c·∫•p b·∫£n sao {context}.",
                    "B·∫°n ƒë∆∞·ª£c ph√©p x√≥a {context} c·ªßa m√¨nh kh·ªèi h·ªá th·ªëng {company} b·∫•t k·ª≥ l√∫c n√†o.",
                ],
                'business': [
                    "{company} cho ph√©p b·∫°n t·∫£i v·ªÅ d·ªØ li·ªáu {context} c·ªßa m√¨nh.",
                    "N·∫øu kh√¥ng mu·ªën ti·∫øp t·ª•c, b·∫°n c√≥ th·ªÉ y√™u c·∫ßu x√≥a {context}.",
                ],
                'casual': [
                    "B·∫°n mu·ªën xem ho·∫∑c x√≥a {context}, c·ª© li√™n h·ªá m√¨nh nh√©.",
                    "{company} s·∫Ω g·ª≠i {context} cho b·∫°n n·∫øu b·∫°n c·∫ßn.",
                ]
            }
        }
        
        templates = NO_KEYWORD_TEMPLATES[category_id][formality]
        selected = random.choice(templates)
        filled_text = self._fill_with_regional_context(selected, region)
        
        return {
            'text': filled_text,
            'label': category_id,
            'ambiguity': 'HARD',
            'difficulty_reason': 'No obvious keywords, semantic understanding required'
        }
```

---

## üìä Recommended Dataset Composition for Vietnamese Models

### **Training Set (75% of data)**

```python
TRAINING_COMPOSITION = {
    'VERY_HARD': 0.30,    # 30% multi-principle overlap scenarios
    'HARD': 0.40,         # 40% no-keyword, semantic understanding
    'MEDIUM': 0.20,       # 20% subtle keywords, some ambiguity
    'EASY': 0.10,         # 10% clear examples (for baseline learning)
}

# Total: 5,000 training samples per category
# VERY_HARD: 1,500 samples
# HARD: 2,000 samples
# MEDIUM: 1,000 samples
# EASY: 500 samples
```

### **Validation Set (15% of data)**

```python
VALIDATION_COMPOSITION = {
    'VERY_HARD': 0.40,    # Higher proportion of hard samples for robust validation
    'HARD': 0.40,
    'MEDIUM': 0.15,
    'EASY': 0.05,
}

# Total: 1,000 validation samples per category
```

### **Test Set (10% of data)**

```python
TEST_COMPOSITION = {
    'VERY_HARD': 0.50,    # Majority hard samples to test generalization
    'HARD': 0.35,
    'MEDIUM': 0.10,
    'EASY': 0.05,
}

# Total: 800 test samples per category
```

---

## üéØ Expected Model Performance with Hard Dataset

### **Realistic Target Accuracy** (vs 100% on easy dataset)

| Dataset Type | Training Acc | Validation Acc | Test Acc | Production Expectation |
|--------------|--------------|----------------|----------|------------------------|
| **Current (Easy)** | 100% | 100% | 100% | 60-70% (overfitting) |
| **Hard (Proposed)** | 82-88% | 78-85% | 75-82% | 75-82% (generalizes!) |

### **Why Lower Accuracy is BETTER**:

‚úÖ **Generalization**: Model learns context, not keywords  
‚úÖ **Production-Ready**: Handles real Vietnamese business documents  
‚úÖ **Robust**: Works with regional variations and ambiguity  
‚úÖ **Investor-Confident**: Realistic performance metrics  

‚ùå **100% accuracy** = Overfitting to synthetic templates (NOT production-ready)

---

## üöÄ Implementation Steps

### **Step 1: Update VeriAIDPO_Colab_Training_CLEAN.ipynb**

Replace `VietnameseTemplateGenerator` with `VietnameseHardDatasetGenerator`

### **Step 2: Generate Hard Dataset**

```python
generator = VietnameseHardDatasetGenerator()

hard_dataset = []
for category_id in range(8):
    # 5000 samples per category with controlled ambiguity
    for ambiguity, count in [
        ('VERY_HARD', 1500),
        ('HARD', 2000),
        ('MEDIUM', 1000),
        ('EASY', 500)
    ]:
        for _ in range(count):
            sample = generator.generate_hard_sample(
                category_id, 
                ambiguity=ambiguity,
                region=random.choice(['north', 'central', 'south']),
                formality=random.choice(['legal', 'formal', 'business', 'casual'])
            )
            hard_dataset.append(sample)
```

### **Step 3: Train VeriAIDPO_Principles_VI with Hard Dataset**

Expected timeline: 2-3 days (same as easy dataset)  
Expected accuracy: **78-88%** (realistic, production-grade)

### **Step 4: Validate on Real Vietnamese Documents**

Test model on actual Vietnamese privacy policies, terms of service, compliance documents

---

## ‚úÖ Success Criteria

### **Model Performance**:
- ‚úÖ **Training Accuracy**: 82-88% (not 100%)
- ‚úÖ **Validation Accuracy**: 78-85%
- ‚úÖ **Test Accuracy**: 75-82%
- ‚úÖ **Real Document Accuracy**: 70-80% (acceptable for production)

### **Dataset Quality**:
- ‚úÖ 30% samples have multi-principle overlap
- ‚úÖ 40% samples have no obvious keywords
- ‚úÖ 100% samples use realistic Vietnamese business language
- ‚úÖ Regional variation coverage: 33% North, 33% Central, 33% South

### **Model Robustness**:
- ‚úÖ Handles formal legal Vietnamese (government documents)
- ‚úÖ Handles casual business Vietnamese (startup policies)
- ‚úÖ Correctly identifies PRIMARY principle in overlapping scenarios
- ‚úÖ No keyword dependency (semantic understanding)

---

## üè¢ Company Name Strategy: Dynamic Registry Integration

### **Overview**

All dataset generation uses **REAL Vietnamese company names** from the Dynamic Company Registry, then normalizes them during training to enable zero-retraining scalability.

### **Why Real Company Names?**

**Production Realism:**
- Vietnamese businesses use specific brand names in compliance contexts
- Regional patterns: "Vietcombank t·∫°i chi nh√°nh H√† N·ªôi" vs "VCB ·ªü chi nh√°nh TPHCM"
- Industry-specific terminology: FinTech (MoMo, ZaloPay) vs Healthcare (Vinmec, FV Hospital)

**Training Quality:**
- Models learn real Vietnamese business language patterns
- Captures authentic company-context relationships
- Reflects actual compliance documentation style

### **Company Selection Strategy**

```python
class VietnameseHardDatasetGenerator:
    """
    Enhanced with Dynamic Company Registry integration
    """
    
    def __init__(self):
        from app.core.company_registry import CompanyRegistry
        
        self.company_registry = CompanyRegistry()
        self.ambiguity_levels = ['EASY', 'MEDIUM', 'HARD', 'VERY_HARD']
        
    def _select_company_for_context(
        self, 
        industry: str,
        region: str = None,
        company_size: str = None
    ) -> str:
        """
        Select appropriate Vietnamese company from registry
        based on industry, region, and size context
        """
        
        # Get companies matching industry
        companies = self.company_registry.get_companies_by_industry(industry)
        
        # Filter by region if specified
        if region:
            companies = [c for c in companies if region in c.get('regions', [])]
        
        # Filter by size if specified
        if company_size:
            companies = [c for c in companies if c.get('size') == company_size]
        
        # Randomly select from matching companies
        import random
        return random.choice(companies)['name']
    
    def generate_financial_sample(self, region: str) -> Dict:
        """
        Example: Generate financial sector sample with real bank
        """
        
        # Select real Vietnamese bank
        company = self._select_company_for_context(
            industry='finance',
            region=region,
            company_size='large'
        )
        # Returns: "Vietcombank", "BIDV", "Techcombank", etc.
        
        # Generate sample with real company name
        text = f"""CƒÉn c·ª© h·ª£p ƒë·ªìng m·ªü t√†i kho·∫£n, {company} thu th·∫≠p CMND/CCCD, 
        gi·∫•y t·ªù ch·ª©ng minh thu nh·∫≠p, v√† th√¥ng tin li√™n h·ªá c·ªßa kh√°ch h√†ng. 
        Th√¥ng tin n√†y ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ th·∫©m ƒë·ªãnh h·ªì s∆° vay v·ªën theo quy ƒë·ªãnh 
        c·ªßa Ng√¢n h√†ng Nh√† n∆∞·ªõc."""
        
        return {
            'text': text,
            'category_id': 1,  # Contractual Necessity
            'company': company,  # Metadata for tracking
            'industry': 'finance',
            'region': region
        }
```

### **Industry-Company Mapping**

The Dynamic Company Registry includes **150+ Vietnamese companies** across 9 industries:

| Industry | Count | Examples | Context Usage |
|----------|-------|----------|---------------|
| **Technology** | 30-40 | Shopee, Tiki, Grab, VNG, FPT, Viettel | E-commerce, ride-hailing, telecom compliance |
| **Finance** | 25-30 | VCB, BIDV, Techcombank, MoMo, ZaloPay | Banking, FinTech, payment processing |
| **Healthcare** | 15-20 | Vinmec, FV Hospital, B·ªánh vi·ªán B·∫°ch Mai | Medical records, telemedicine, health apps |
| **Education** | 10-12 | ELSA, Topica, CoderSchool | EdTech, student data, learning analytics |
| **Retail** | 15-20 | VinMart, Co.opmart, BigC, Sendo | Loyalty programs, customer data |
| **Transportation** | 8-10 | Vietnam Airlines, Vietjet, GSM Logistics | Passenger data, tracking systems |
| **Real Estate** | 8-10 | Vingroup, Novaland, H∆∞ng Th·ªãnh | Property transactions, customer CRM |
| **Telecom** | 5-7 | Viettel, VNPT, MobiFone, VinaPhone | Subscriber data, usage analytics |
| **Government** | 5-8 | B·ªô Y t·∫ø, B·ªô GD&ƒêT, UBND TPHCM | Citizen data, public services |

### **Regional Company Selection**

**North (Hanoi) - 33% of samples:**
```python
# Formal, government-aligned companies
north_examples = [
    "Vietcombank",  # State-owned bank
    "BIDV",         # State-owned bank
    "Viettel",      # Military-owned telecom
    "VNPT",         # State telecom
    "B·ªánh vi·ªán B·∫°ch Mai"  # Government hospital
]
```

**Central (Da Nang/Hue) - 33% of samples:**
```python
# Traditional businesses, tourism, government services
central_examples = [
    "FPT",                    # Tech company HQ in Da Nang
    "Vingroup",               # Tourism/hospitality
    "B·ªánh vi·ªán ƒê√† N·∫µng",      # Regional hospital
    "UBND Th·ª´a Thi√™n Hu·∫ø"     # Provincial government
]
```

**South (HCMC) - 33% of samples:**
```python
# Entrepreneurial, startup, international businesses
south_examples = [
    "Shopee",           # E-commerce startup
    "Grab",             # Ride-hailing
    "Techcombank",      # Private bank
    "MoMo",             # FinTech startup
    "Vinmec",           # Private healthcare
    "ELSA"              # EdTech startup
]
```

### **Normalization Pipeline (Separate from Generation)**

**CRITICAL**: Dataset generation uses REAL company names. Normalization happens during model training:

```python
# Step 1: GENERATION (this guide) - Use real companies
sample = {
    'text': "MoMo thu th·∫≠p CMND c·ªßa kh√°ch h√†ng ƒë·ªÉ x√°c th·ª±c t√†i kho·∫£n...",
    'category_id': 1,
    'company': 'MoMo'
}

# Step 2: NORMALIZATION (training pipeline) - Replace with token
from app.core.text_normalizer import PDPLTextNormalizer

normalizer = PDPLTextNormalizer()
normalized_text = normalizer.normalize_company_names(sample['text'])
# Result: "[COMPANY] thu th·∫≠p CMND c·ªßa kh√°ch h√†ng ƒë·ªÉ x√°c th·ª±c t√†i kho·∫£n..."

# Step 3: TRAINING - Model learns company-agnostic patterns
training_sample = {
    'text': normalized_text,
    'category_id': 1
}
```

### **Benefits of This Approach**

**1. Production Realism During Training:**
- Models see authentic Vietnamese business language
- Learn regional variations (VCB vs Vietcombank vs Ng√¢n h√†ng TMCP Ngo·∫°i th∆∞∆°ng Vi·ªát Nam)
- Understand industry-specific contexts

**2. Company-Agnostic Prediction:**
- After normalization, model works with ANY company name
- No bias toward specific brands
- Generalizes to unseen companies

**3. Zero-Retraining Scalability:**
- Add new companies to registry: 5 minutes, $0 cost
- No model retraining required
- Future-proof architecture

**4. Cost Savings:**
- Traditional approach (hardcoded): $220-320 + 7 weeks per company update
- Dynamic registry: $0 + 5 minutes for unlimited company additions
- **Lifetime savings**: $440-640 + 14 weeks for just 3 company updates

### **Implementation References**

**Full Architecture**: See `VeriAIDPO_Dynamic_Company_Registry_Implementation.md` for:
- CompanyRegistry class implementation (500+ LOC)
- PDPLTextNormalizer class implementation (300+ LOC)
- Admin API for company management (7 endpoints)
- Classification API integration with normalization
- Testing suite and deployment guide

**Company Registry File**: `config/company_registry.json`
```json
{
  "companies": [
    {
      "id": "vietcombank",
      "name": "Vietcombank",
      "aliases": ["VCB", "Ng√¢n h√†ng TMCP Ngo·∫°i th∆∞∆°ng Vi·ªát Nam"],
      "industry": "finance",
      "regions": ["north", "central", "south"],
      "size": "large",
      "type": "state-owned"
    },
    {
      "id": "momo",
      "name": "MoMo",
      "aliases": ["V√≠ MoMo", "M-Service"],
      "industry": "finance",
      "regions": ["south"],
      "size": "startup",
      "type": "private"
    }
    // ... 148+ more Vietnamese companies
  ]
}
```

### **Dataset Generation Workflow**

```bash
# 1. Load Company Registry
python -c "from app.core.company_registry import CompanyRegistry; 
           registry = CompanyRegistry(); 
           print(f'Loaded {len(registry.get_all_companies())} companies')"

# 2. Generate Hard Dataset with Real Companies
python scripts/generate_hard_dataset.py \
    --model-type VeriAIDPO_Principles \
    --language vi \
    --total-samples 24000 \
    --use-company-registry \
    --output datasets/vietnamese_pdpl_hard_principles.jsonl

# 3. Verify Company Distribution
python scripts/validate_dataset.py \
    --dataset datasets/vietnamese_pdpl_hard_principles.jsonl \
    --check-company-coverage

# 4. Train with Normalization
python scripts/train_model.py \
    --dataset datasets/vietnamese_pdpl_hard_principles.jsonl \
    --normalize-companies \
    --output models/VeriAIDPO_Principles_VI_v2

# 5. Add New Company (Anytime, Zero Retraining)
curl -X POST http://localhost:8000/api/v1/admin/companies/add \
    -H "Content-Type: application/json" \
    -d '{
      "name": "VPBank",
      "aliases": ["VP Bank", "Ng√¢n h√†ng TMCP Vi·ªát Nam Th·ªãnh V∆∞·ª£ng"],
      "industry": "finance",
      "regions": ["north", "central", "south"],
      "size": "large"
    }'
```

### **Quality Validation**

After implementing Dynamic Company Registry, validate:

- ‚úÖ **Company Coverage**: All 150+ Vietnamese brands in registry
- ‚úÖ **Industry Distribution**: Matches production reality (25% tech, 20% finance, etc.)
- ‚úÖ **Regional Balance**: 33% North, 33% Central, 33% South
- ‚úÖ **Normalization Accuracy**: 99.9%+ company name detection rate
- ‚úÖ **Model Performance**: No degradation vs hardcoded approach
- ‚úÖ **Inference Speed**: <100ms including normalization overhead

---

## üìù Next Steps

1. **Review this guide** and approve hard dataset strategy
2. **Update training notebook** with `VietnameseHardDatasetGenerator`
3. **Generate hard dataset** (40,000 samples total, 8 categories √ó 5,000)
4. **Train VeriAIDPO_Principles_VI** with hard dataset
5. **Validate** on real Vietnamese compliance documents
6. **Apply same strategy** to all 10 additional model types (Legal Basis, Breach Triage, etc.)

---

**Document Owner**: VeriSyntra ML Team  
**Last Updated**: October 14, 2025  
**Status**: üìã Ready for Implementation  
**Priority**: üö® HIGH - Critical for Production Readiness
